# Loading and Transforming Customer Reviews for RAG (ê³ ê° ë¦¬ë·° ë¡œë“œ ë° ë³€í™˜)

# 0. ëª©í‘œ

<aside>
ğŸ’¡

**Day 16ì—ì„œ ì €ì¥í•œ ê³ ê° ë¦¬ë·°ë¥¼ ë¡œë“œí•˜ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë³€í™˜**

1. Snowflakeì—ì„œ ê³ ê° ë¦¬ë·° ë°ì´í„° ë¡œë“œ
2. ë‘ ê°€ì§€ ì²˜ë¦¬ ì „ëµ ì œê³µ (ë¦¬ë·°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€ vs ê¸´ ë¦¬ë·° ë¶„í• )
3. ì²­í¬ë¥¼ Snowflake í…Œì´ë¸”ì— ì €ì¥í•˜ì—¬ Day 18 ì„ë² ë”© ìƒì„± ì¤€ë¹„

</aside>

# 1. ê°œìš” ë° í•„ìš”ì„± (Overview)

- RAG íŒŒì´í”„ë¼ì¸ì˜ **ë‘ ë²ˆì§¸ ë‹¨ê³„**ë¡œ, ì¶”ì¶œëœ ë¬¸ì„œë¥¼ ì„ë² ë”©ì— ì í•©í•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
- ê³ ê° ë¦¬ë·°ëŠ” ë³´í†µ ì§§ê¸° ë•Œë¬¸ì—(~50-150ë‹¨ì–´), ê° ë¦¬ë·°ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
- í•„ìš”ì‹œ ê¸´ ë¦¬ë·°ë¥¼ ì¤‘ë³µ(overlap)ì´ ìˆëŠ” ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

# 2. Streamlit ì•± êµ¬í˜„ (Implementation)

## 2-1. Day 16 ë°ì´í„° ë¡œë“œ

```python
import streamlit as st
import pandas as pd

# Snowflake ì—°ê²°
try:
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
except:
    from snowflake.snowpark import Session
    session = Session.builder.configs(st.secrets["connections"]["snowflake"]).create()

# Day 16ì˜ í…Œì´ë¸” ì°¸ì¡° í™•ì¸
if 'day17_database' not in st.session_state:
    if 'rag_source_database' in st.session_state:
        st.session_state.day17_database = st.session_state.rag_source_database
        st.session_state.day17_schema = st.session_state.rag_source_schema
    else:
        st.session_state.day17_database = "RAG_DB"
        st.session_state.day17_schema = "RAG_SCHEMA"

# ë¬¸ì„œ ë¡œë“œ ë²„íŠ¼
if st.button(":material/folder_open: Load Reviews", type="primary"):
    query = f"""
    SELECT DOC_ID, FILE_NAME, FILE_TYPE, EXTRACTED_TEXT,
           UPLOAD_TIMESTAMP, WORD_COUNT, CHAR_COUNT
    FROM {st.session_state.day17_database}.{st.session_state.day17_schema}.{st.session_state.day17_table_name}
    ORDER BY FILE_NAME
    """
    df = session.sql(query).to_pandas()
    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.loaded_data = df
    st.rerun()
```

- Day 16ì—ì„œ ì €ì¥í•œ `rag_source_database`ì™€ `rag_source_schema`ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€
- `EXTRACTED_TEXT` ì»¬ëŸ¼ì—ì„œ ì „ì²´ ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
- `.to_pandas()`: Snowflake ê²°ê³¼ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ Pythonì—ì„œ ì‰½ê²Œ ì²˜ë¦¬

## 2-2. ì²˜ë¦¬ ì „ëµ ì„ íƒ

```python
processing_option = st.radio(
    "Select processing strategy:",
    ["Keep each review as a single chunk (Recommended)", 
     "Chunk reviews longer than threshold"],
    index=0
)

# ì²­í¬ í¬ê¸° ì»¨íŠ¸ë¡¤ ì¶”ê°€ (ì²­í¬ ì˜µì…˜ ì„ íƒ ì‹œì—ë§Œ í‘œì‹œ)
if "Chunk reviews" in processing_option:
    chunk_size = st.slider("Chunk Size (words):", 50, 500, 200, 50)
    overlap = st.slider("Overlap (words):", 0, 100, 50, 10)
```

- **ì˜µì…˜ 1 (ê¶Œì¥)**: ê° ë¦¬ë·°ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìœ ì§€ - ì§§ì€ ê³ ê° ë¦¬ë·°ì— ìµœì 
- **ì˜µì…˜ 2**: ê¸´ ë¦¬ë·°ë¥¼ ë¶„í•  - 200ë‹¨ì–´ ì´ìƒì˜ ë¦¬ë·°ë¥¼ ì¤‘ë³µì´ ìˆëŠ” ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ”
- `index=0`: ì²« ë²ˆì§¸ ì˜µì…˜(ë¦¬ë·° ê·¸ëŒ€ë¡œ ìœ ì§€)ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
- ìŠ¬ë¼ì´ë”ëŠ” ë‘ ë²ˆì§¸ ì˜µì…˜ì„ ì„ íƒí–ˆì„ ë•Œë§Œ í‘œì‹œë¨

## 2-3. ì²­í¬ ìƒì„±

```python
chunks = []

if "Keep each review" in processing_option:
    # ì˜µì…˜ 1: ë¦¬ë·° 1ê°œ = ì²­í¬ 1ê°œ
    for idx, row in df.iterrows():
        chunks.append({
            'chunk_id': idx + 1,
            'doc_id': row['DOC_ID'],
            'file_name': row['FILE_NAME'],
            'chunk_text': row['EXTRACTED_TEXT'],
            'chunk_size': row['WORD_COUNT'],
            'chunk_type': 'full_review'
        })
else:
    # ì˜µì…˜ 2: ê¸´ ë¦¬ë·°ë¥¼ ì²­í¬ë¡œ ë¶„í• 
    chunk_id = 1
    for idx, row in df.iterrows():
        text = row['EXTRACTED_TEXT']
        words = text.split()
        
        if len(words) <= chunk_size:
            # ì§§ì€ ë¦¬ë·°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
            chunks.append({
                'chunk_id': chunk_id,
                'chunk_text': text,
                'chunk_size': len(words),
                'chunk_type': 'full_review'
            })
            chunk_id += 1
        else:
            # ê¸´ ë¦¬ë·° ë¶„í• 
            for i in range(0, len(words), chunk_size - overlap):
                chunk_words = words[i:i + chunk_size]
                chunk_text = ' '.join(chunk_words)
                chunks.append({
                    'chunk_id': chunk_id,
                    'chunk_text': chunk_text,
                    'chunk_size': len(chunk_words),
                    'chunk_type': 'chunked_review'
                })
                chunk_id += 1
```

- **ì˜µì…˜ 1**: ê° ë¦¬ë·°ì˜ `EXTRACTED_TEXT`ë¥¼ ê·¸ëŒ€ë¡œ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ë³µì‚¬ (100ê°œ ë¦¬ë·° = 100ê°œ ì²­í¬)
- **ì˜µì…˜ 2**: í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ë¡œ ë¶„í• í•œ í›„ `range(0, len(words), chunk_size - overlap)`ë¡œ ì¤‘ë³µ ì²­í¬ ìƒì„±
- **ì¤‘ë³µ ê³„ì‚°**: chunk_size=200, overlap=50ì´ë©´ 150ë‹¨ì–´ì”© ì´ë™ (200-50=150)
- `chunk_type`: ì¶”ì ì„ ìœ„í•´ `'full_review'` ë˜ëŠ” `'chunked_review'`ë¡œ ë ˆì´ë¸” ì§€ì •

## 2-4. Replace Mode (êµì²´ ëª¨ë“œ) ê´€ë¦¬

```python
# í…Œì´ë¸” ìƒíƒœì— ë”°ë¼ ì²´í¬ë°•ìŠ¤ ìƒíƒœ ì´ˆê¸°í™” ë˜ëŠ” ì—…ë°ì´íŠ¸
if 'day17_replace_mode' not in st.session_state:
    # ì²˜ìŒ - í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¼ ì´ˆê¸°í™”
    st.session_state.day17_replace_mode = chunk_table_exists
else:
    # í…Œì´ë¸” ì´ë¦„ ë³€ê²½ í™•ì¸ - ë³€ê²½ ì‹œ ìƒˆ í…Œì´ë¸” ìƒíƒœì— ë”°ë¼ ë¦¬ì…‹
    if st.session_state.get('day17_last_chunk_table') != full_chunk_table:
        st.session_state.day17_replace_mode = chunk_table_exists
        st.session_state.day17_last_chunk_table = full_chunk_table

# êµì²´ ëª¨ë“œ ì²´í¬ë°•ìŠ¤
replace_mode = st.checkbox(
    f":material/sync: Replace Table Mode for `{st.session_state.day17_chunk_table}`",
    key="day17_replace_mode"
)
```

- ì²­í¬ í…Œì´ë¸”ì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì²´í¬ë°•ìŠ¤ê°€ ê¸°ë³¸ìœ¼ë¡œ ì²´í¬ë¨
- í…Œì´ë¸” ì´ë¦„ì´ ë³€ê²½ë˜ë©´ ìƒˆ í…Œì´ë¸”ì˜ ìƒíƒœì— ë”°ë¼ ì²´í¬ë°•ìŠ¤ ë¦¬ì…‹
- `key="day17_replace_mode"`: ì„¸ì…˜ ìƒíƒœì™€ ì—°ê²°í•˜ì—¬ í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì œì–´ ê°€ëŠ¥

## 2-5. Snowflakeì— ì²­í¬ ì €ì¥

```python
# 1ë‹¨ê³„: í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
create_table_sql = f"""
CREATE TABLE IF NOT EXISTS {full_chunk_table} (
    CHUNK_ID NUMBER,
    DOC_ID NUMBER,
    FILE_NAME VARCHAR,
    CHUNK_TEXT VARCHAR,
    CHUNK_SIZE NUMBER,
    CHUNK_TYPE VARCHAR,
    CREATED_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
)
"""
session.sql(create_table_sql).collect()

# 2ë‹¨ê³„: êµì²´ ëª¨ë“œ - ê¸°ì¡´ ì²­í¬ ì‚­ì œ
if replace_mode:
    session.sql(f"TRUNCATE TABLE {full_chunk_table}").collect()

# 3ë‹¨ê³„: ì²­í¬ ì‚½ì…
chunks_df = pd.DataFrame(chunks)

# Snowflake í…Œì´ë¸”ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì—´ ì´ë¦„ì„ ëŒ€ë¬¸ìë¡œ ë³€ê²½
chunks_df_upper = chunks_df[['chunk_id', 'doc_id', 'file_name', 
                              'chunk_text', 'chunk_size', 'chunk_type']].copy()
chunks_df_upper.columns = ['CHUNK_ID', 'DOC_ID', 'FILE_NAME', 
                            'CHUNK_TEXT', 'CHUNK_SIZE', 'CHUNK_TYPE']

# Snowflakeì— ì“°ê¸°
session.write_pandas(chunks_df_upper,
                    table_name=st.session_state.day17_chunk_table,
                    database=st.session_state.day17_database,
                    schema=st.session_state.day17_schema,
                    overwrite=replace_mode)
```

- `CHUNK_TEXT`: Day 18ì—ì„œ ì„ë² ë”©í•  ì‹¤ì œ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥
- `session.write_pandas()`: 100ê°œ ì´ìƒì˜ ì²­í¬ë¥¼ ê°œë³„ INSERT ë¬¸ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ ì¼ê´„ ì‚½ì…
- `overwrite=replace_mode`: Trueë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì‚½ì…, Falseë©´ ì¶”ê°€

## 2-6. ì €ì¥ëœ ì²­í¬ í™•ì¸

```python
if st.button(":material/analytics: Query Chunk Table"):
    chunks_df = session.sql(f"""
        SELECT CHUNK_ID, FILE_NAME, CHUNK_SIZE, CHUNK_TYPE,
               LEFT(CHUNK_TEXT, 100) AS TEXT_PREVIEW
        FROM {full_chunk_table}
        ORDER BY CHUNK_ID
    """).to_pandas()
    st.session_state.queried_chunks = chunks_df
    st.rerun()

# ì „ì²´ ì²­í¬ í…ìŠ¤íŠ¸ ë³´ê¸°
chunk_id = st.selectbox("Select Chunk ID:", options=chunks_df['CHUNK_ID'].tolist())

if st.button("Load Chunk Text"):
    text_result = session.sql(f"""
        SELECT CHUNK_TEXT FROM {full_chunk_table} 
        WHERE CHUNK_ID = {chunk_id}
    """).collect()
    chunk_text = text_result[0]['CHUNK_TEXT']
    st.text_area("Full Chunk Text", value=chunk_text, height=300)
```

- `LEFT(CHUNK_TEXT, 100)`: ê° ì²­í¬ì˜ ì²˜ìŒ 100ìë§Œ ë¯¸ë¦¬ë³´ê¸°ë¡œ í‘œì‹œ
- íŠ¹ì • ì²­í¬ì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì˜µì…˜
- ì²­í¬ê°€ ì˜¬ë°”ë¥´ê²Œ ì €ì¥ë˜ì—ˆê³  ì˜ˆìƒëœ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸

# 3. í•µì‹¬ í¬ì¸íŠ¸ ë° ê³ ë ¤ì‚¬í•­

## ì²­í¬ ì „ëµ (Chunking Strategy)

- ì§§ì€ ê³ ê° ë¦¬ë·°(50-150ë‹¨ì–´)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ìµœì 
- ê¸´ ë¬¸ì„œì˜ ê²½ìš° ì¤‘ë³µ(overlap)ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ë§¥ ì—°ì†ì„± ìœ ì§€

## Day 18ê³¼ì˜ í†µí•©

```python
st.session_state.chunks_table = f"{database}.{schema}.{chunk_table}"
st.session_state.chunks_database = database
st.session_state.chunks_schema = schema
```

- Day 18ì´ ìë™ìœ¼ë¡œ ì´ ì²­í¬ í…Œì´ë¸”ì„ ì°¾ì•„ ì„ë² ë”© ìƒì„±

## í…Œì´ë¸” ê´€ë¦¬

- Replace vs Append ëª¨ë“œë¡œ ë°ì´í„° ê´€ë¦¬ ì „ëµ ì œê³µ
- í…Œì´ë¸” ìƒíƒœì— ë”°ë¼ ì²´í¬ë°•ìŠ¤ ê¸°ë³¸ê°’ ìë™ ì„¤ì •

# ì‹¤í–‰ ê²°ê³¼

## ì‹¤í–‰ ì½”ë“œ

Streamlit ì‹¤í–‰ ì½”ë“œ = python -m streamlit run íŒŒì¼ëª….py

ì˜ˆì‹œ : `python -m streamlit run app/day17.py`

## ê²°ê³¼

- Day 16ì˜ 100ê°œ ë¦¬ë·°ë¥¼ 100ê°œ ì²­í¬ë¡œ ë³€í™˜ (ë˜ëŠ” í•„ìš”ì‹œ ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í• )
- Snowflakeì˜ `REVIEW_CHUNKS` í…Œì´ë¸”ì— ì €ì¥
- ê° ì²­í¬ëŠ” ì ì ˆí•œ í¬ê¸°ë¡œ ì„ë² ë”© ìƒì„± ì¤€ë¹„ ì™„ë£Œ
- Day 18ì—ì„œ ì´ ì²­í¬ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ê°€ëŠ¥
