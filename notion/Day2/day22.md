# ë‚´ ë¬¸ì„œì™€ ì±„íŒ…í•˜ê¸° (Chat with Your Documents)

# 0. ëª©í‘œ

<aside>
ğŸ’¡

**ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¡œ ë¬¸ì„œ ê¸°ë°˜(RAG) ì±—ë´‡ êµ¬í˜„**

1. Streamlit ì±„íŒ… UI êµ¬ì„± (st.chat_input, st.chat_message)
2. ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (Session State)
3. RAG íŒŒì´í”„ë¼ì¸ê³¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í†µí•©

</aside>

# 1. ê°œìš” (Overview)

- **ëŒ€í™”í˜• RAG**: ë‹¨ì¼ ì§ˆë¬¸-ë‹µë³€ì„ ë„˜ì–´, ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
- **í†µí•©**: Day 19-21ì—ì„œ êµ¬ì¶•í•œ ê²€ìƒ‰ ë° ìƒì„± ê¸°ëŠ¥ì„ ì¹œìˆ™í•œ ì±„íŒ… UIë¡œ ì œê³µí•©ë‹ˆë‹¤.
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: ì±—ë´‡ì˜ í˜ë¥´ì†Œë‚˜ì™€ ì œì•½ ì¡°ê±´ì„ ì„¤ì •í•˜ì—¬ ë¬¸ì„œ ë²”ìœ„ ë‚´ì—ì„œë§Œ ë‹µë³€í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.

# 2. Streamlit ì•± êµ¬í˜„ (Implementation)

## 2-1. ì±„íŒ… ê¸°ë¡ ê´€ë¦¬

```python
# ìƒíƒœ ì´ˆê¸°í™”
if "doc_messages" not in st.session_state:
    st.session_state.doc_messages = []

# ...

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.doc_messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
```

- `st.session_state.doc_messages`: ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
- `st.chat_message`: ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©ì(user)ì™€ ì–´ì‹œìŠ¤í„´íŠ¸(assistant) ì—­í• ì— ë”°ë¼ í‘œì‹œí•©ë‹ˆë‹¤.

## 2-2. ê²€ìƒ‰ í•¨ìˆ˜ ëª¨ë“ˆí™”

```python
def search_documents(query, service_path, limit):
    from snowflake.core import Root
    # ... (Cortex Search ì—°ê²° ì„¤ì •) ...
    svc = root.databases[parts[0]].schemas[parts[1]].cortex_search_services[parts[2]]
    results = svc.search(query=query, columns=["CHUNK_TEXT", "FILE_NAME"], limit=limit)
    
    chunks_data = []
    for item in results.results:
        chunks_data.append({
            "text": item.get("CHUNK_TEXT", ""),
            "source": item.get("FILE_NAME", "Unknown")
        })
    return chunks_data
```

- ê²€ìƒ‰ ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ì—¬ ì½”ë“œ ì¬ì‚¬ìš©ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.
- ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ì™€ ì¶œì²˜(íŒŒì¼ëª…)ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

## 2-3. ì±„íŒ… ì…ë ¥ ë° RAG ì‹¤í–‰

```python
if prompt := st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
    # 1. ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ ë° ì €ì¥
    st.session_state.doc_messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # 2. ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ë° ìƒê° ì¤‘..."):
            # ê²€ìƒ‰
            chunks_data = search_documents(prompt, search_service, num_chunks)
            context = "\n\n---\n\n".join([c["text"] for c in chunks_data])
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê°€ë“œë ˆì¼ í¬í•¨)
            rag_prompt = f"""You are a customer review analysis assistant.
STRICT GUIDELINES:
1. ONLY use information from the provided customer review context
2. If context doesn't contain info, say "I don't have enough information"
...
CONTEXT: {context}
QUESTION: {prompt}
"""
            # LLM í˜¸ì¶œ
            sql = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet', '{rag_prompt_escaped}')"
            response = session.sql(sql).collect()[0][0]
            
            # ë‹µë³€ í‘œì‹œ ë° ì €ì¥
            st.markdown(response)
            st.session_state.doc_messages.append({"role": "assistant", "content": response})
```

- `st.chat_input`: ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤. Walrus ì—°ì‚°ì(`:=`)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ í• ë‹¹ê³¼ ì¡°ê±´ í™•ì¸ì„ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤.
- **ì—„ê²©í•œ í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œë¼ì¸**: ì‚¬ìš©ìê°€ ë¬¸ì„œì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì„ í•˜ê±°ë‚˜(ì˜ˆ: ì¼ë°˜ ìƒì‹), í™˜ê°(Hallucination)ì„ ì¼ìœ¼í‚¤ì§€ ì•Šë„ë¡ ì œì•½ ì¡°ê±´ì„ ëª…ì‹œí•©ë‹ˆë‹¤.

# 3. í•µì‹¬ í¬ì¸íŠ¸

## UI/UX ìš”ì†Œ

- **ì¶œì²˜ í‘œì‹œ**: `st.expander`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì— ì‚¬ìš©ëœ ë¬¸ì„œ ì¶œì²˜ë¥¼ ê¹”ë”í•˜ê²Œ í‘œì‹œí•©ë‹¤. ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤.
- **ì±„íŒ… ì§€ìš°ê¸°**: ì‚¬ì´ë“œë°”ì— ë²„íŠ¼ì„ ë‘ì–´ ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ê³  ëŒ€í™”ë¥¼ ìƒˆë¡œ ì‹œì‘í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

## í”„ë¡¬í”„íŠ¸ ì „ëµ

- **ì—­í•  ë¶€ì—¬**: "Customer review analysis assistant"ë¡œ ì—­í• ì„ í•œì •í•©ë‹ˆë‹¤.
- **ì œì•½ ì¡°ê±´**: "ONLY use information from context"ì™€ ê°™ì€ ê°•ë ¥í•œ ì–´ì¡°ë¡œ ì™¸ë¶€ ì§€ì‹ ì‚¬ìš©ì„ ì°¨ë‹¨í•©ë‹ˆë‹¤.
- **ì˜ˆì™¸ ì²˜ë¦¬**: ì •ë³´ê°€ ì—†ì„ ë•Œ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.

# 4. ì‹¤í–‰ ê²°ê³¼

## ì‹¤í–‰ ì½”ë“œ

`python -m streamlit run app/day22.py`

## ê²°ê³¼

- ì‚¬ìš©ìëŠ” ì±„íŒ… ì°½ì„ í†µí•´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ì†ì ì¸ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë´‡ì€ ê²€ìƒ‰ëœ ë¦¬ë·° ë°ì´í„°ì— ê¸°ë°˜í•´ì„œë§Œ ë‹µë³€í•˜ë©°, ì¶œì²˜ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.

---

# ğŸ’¡ ì‹¤ìŠµ ê³¼ì œ (Hands-on Practice)

ë¬¸ì„œ ê²€ìƒ‰ ë¡œì§ì„ ë³„ë„ì˜ í•¨ìˆ˜ë¡œ ëª¨ë“ˆí™”í•˜ì—¬ ì±—ë´‡ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ë´…ë‹ˆë‹¤.

1. `svc.search()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.
2. ê²°ê³¼ì—ì„œ `CHUNK_TEXT`ì™€ `FILE_NAME` ì»¬ëŸ¼ì„ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •í•˜ì„¸ìš”.
3. ê²€ìƒ‰ ê²°ê³¼ë¥¼ `chunks_data` ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

# âœ… ì •ë‹µ ì½”ë“œ (Solution)

```python
# ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„ ì‹¤ìŠµ
def search_documents(query, service_path, limit):
    # ... (Root ë° ì„œë¹„ìŠ¤ ì—°ê²° ì½”ë“œ ìƒëµ) ...
    
    # 1. Cortex Search ì‹¤í–‰
    results = svc.search(
        query=query, 
        columns=["CHUNK_TEXT", "FILE_NAME"], 
        limit=limit
    )
    
    # 2. ë°ì´í„° ì¶”ì¶œ ë° ë°˜í™˜
    chunks_data = []
    for item in results.results:
        chunks_data.append({
            "text": item.get("CHUNK_TEXT", ""),
            "source": item.get("FILE_NAME", "Unknown")
        })
    return chunks_data
```
