# RAG with Cortex Search (Cortex Searchë¥¼ í™œìš©í•œ RAG)

# 0. ëª©í‘œ

<aside>
ğŸ’¡

**ê²€ìƒ‰ ê²°ê³¼ì™€ LLM ìƒì„±ì„ ê²°í•©í•˜ì—¬ ê·¼ê±° ìˆëŠ” ë‹µë³€ ì œê³µ**

1. ì‚¬ìš©ì ì§ˆë¬¸ìœ¼ë¡œ ê´€ë ¨ ë¦¬ë·° ê²€ìƒ‰ (Retrieve)
2. ê²€ìƒ‰ëœ ë¦¬ë·°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ (Augment)
3. LLMìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ë‹µë³€ ìƒì„± (Generate)

</aside>

# 1. ê°œìš” (Overview)

- **RAG (Retrieval-Augmented Generation)**ì˜ ì™„ì „í•œ êµ¬í˜„ì…ë‹ˆë‹¤.
- ë‹¨ìˆœíˆ LLMë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤ì œ ë°ì´í„°(ê³ ê° ë¦¬ë·°)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
- Week 3ì˜ **ìµœì¢… ë‹¨ê³„**ë¡œ, Day 16-20ì—ì„œ êµ¬ì¶•í•œ ëª¨ë“  ìš”ì†Œë¥¼ í†µí•©í•©ë‹ˆë‹¤.

## RAG ì‘ë™ ë°©ì‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Retrieve â”‚  Cortex Searchë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
â”‚  (ê²€ìƒ‰)      â”‚  ì˜ˆ: "ì—´ ì¥ê°‘ì´ ì¶©ë¶„íˆ ë”°ëœ»í•œê°€ìš”?"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Augment  â”‚  ê²€ìƒ‰ëœ ë¦¬ë·°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
â”‚  (ì¦ê°•)      â”‚  "ë‹¤ìŒ ê³ ê° ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì„¸ìš”: ..."
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Generate â”‚  LLMì´ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
â”‚  (ìƒì„±)      â”‚  "ê³ ê° ë¦¬ë·°ì— ë”°ë¥´ë©´ ì—´ ì¥ê°‘ì€..."
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

# 2. Streamlit ì•± êµ¬í˜„ (Implementation)

## 2-1. ì‚¬ì´ë“œë°” ì„¤ì •

```python
import streamlit as st

# Snowflake ì—°ê²°
try:
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
except:
    from snowflake.snowpark import Session
    session = Session.builder.configs(st.secrets["connections"]["snowflake"]).create()

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header(":material/settings: Settings")
    
    # Day 19ì˜ ê¸°ë³¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤
    default_service = 'RAG_DB.RAG_SCHEMA.CUSTOMER_REVIEW_SEARCH'
    
    # ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì„ íƒ
    search_service = st.selectbox(
        "Search Service:",
        options=available_services,
        index=0
    )
    
    num_chunks = st.slider("Context chunks:", 1, 10, 3,
                           help="Number of relevant chunks to retrieve")
    
    model = st.selectbox(
        "LLM Model:",
        ["claude-3-5-sonnet", "mistral-large", "llama3.1-8b"],
        help="Model to generate the answer"
    )
    
    show_context = st.checkbox("Show retrieved context", value=True)
```

- ê²€ìƒ‰ ì„œë¹„ìŠ¤, ì»¨í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜, LLM ëª¨ë¸ ì„ íƒ
- ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ í‘œì‹œ ì—¬ë¶€ í† ê¸€

## 2-2. ì§ˆë¬¸ ì…ë ¥

```python
# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
question = st.text_input(
    "Your question:",
    value="Are the thermal gloves warm enough for winter?",
    placeholder="e.g., Which products have durability issues?"
)

if st.button(":material/search: Search & Answer", type="primary"):
    # RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘
```

- ê¸°ë³¸ ì§ˆë¬¸: "ì—´ ì¥ê°‘ì´ ê²¨ìš¸ì— ì¶©ë¶„íˆ ë”°ëœ»í•œê°€ìš”?"
- ì‚¬ìš©ìê°€ ììœ ë¡­ê²Œ ì§ˆë¬¸ ì…ë ¥ ê°€ëŠ¥

## 2-3. 1ë‹¨ê³„: Cortex Searchì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰

```python
if question and search_service:
    with st.status("Processing...", expanded=True) as status:
        # 1ë‹¨ê³„: Cortex Searchì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        st.write(":material/search: **Step 1:** Searching documents...")
        
        from snowflake.core import Root
        
        root = Root(session)
        parts = search_service.split(".")
        
        svc = (root
            .databases[parts[0]]
            .schemas[parts[1]]
            .cortex_search_services[parts[2]])
        
        search_results = svc.search(
            query=question,
            columns=["CHUNK_TEXT", "FILE_NAME"],
            limit=num_chunks
        )
        
        # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context_chunks = []
        sources = []
        for item in search_results.results:
            context_chunks.append(item.get("CHUNK_TEXT", ""))
            sources.append(item.get("FILE_NAME", "Unknown"))
        
        context = "\n\n---\n\n".join(context_chunks)
        
        st.write(f"   :material/check_circle: Found {len(context_chunks)} relevant chunks")
```

- ì‚¬ìš©ì ì§ˆë¬¸ìœ¼ë¡œ Cortex Search ì‹¤í–‰
- ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ Nê°œ ì²­í¬ ê²€ìƒ‰ (ê¸°ë³¸ 3ê°œ)
- ì²­í¬ í…ìŠ¤íŠ¸ì™€ ì¶œì²˜ íŒŒì¼ëª… ì¶”ì¶œ
- `"\n\n---\n\n"`ë¡œ ì²­í¬ êµ¬ë¶„í•˜ì—¬ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©

## 2-4. 2ë‹¨ê³„: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±

```python
        # 2ë‹¨ê³„: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
        st.write(":material/smart_toy: **Step 2:** Generating answer...")
        
        rag_prompt = f"""You are a helpful assistant. Answer the user's question based ONLY on the provided context.
If the context doesn't contain enough information to answer, say "I don't have enough information to answer that based on the available documents."

CONTEXT FROM DOCUMENTS:
{context}

USER QUESTION: {question}

Provide a clear, accurate answer based on the context. If you use information from the context, mention it naturally."""
        
        # LLM í˜¸ì¶œ
        response_sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{model}',
            '{rag_prompt.replace("'", "''")}'
        ) as response
        """
        
        response = session.sql(response_sql).collect()[0][0]
        
        st.write("   :material/check_circle: Answer generated")
```

- í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ì»¨í…ìŠ¤íŠ¸ + ì‚¬ìš©ì ì§ˆë¬¸
- **ì¤‘ìš” ì§€ì‹œì‚¬í•­**: "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë§Œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€"
- ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ë„ë¡ ì§€ì‹œ
- `SNOWFLAKE.CORTEX.COMPLETE()`ë¡œ LLM í˜¸ì¶œ
- `.replace("'", "''")`: SQL ì¸ì ì…˜ ë°©ì§€ë¥¼ ìœ„í•œ ì´ìŠ¤ì¼€ì´í”„

## 2-5. ê²°ê³¼ í‘œì‹œ

```python
        # ê²°ê³¼ í‘œì‹œ
        st.divider()
        
        st.subheader(":material/lightbulb: Answer")
        with st.container(border=True):
            st.markdown(response)
        
        if show_context:
            st.subheader(":material/library_books: Retrieved Context")
            st.caption(f"Used {len(context_chunks)} chunks from customer reviews")
            for i, (chunk, source) in enumerate(zip(context_chunks, sources), 1):
                with st.expander(f":material/description: Chunk {i} - {source}"):
                    st.write(chunk)
```

- ìƒì„±ëœ ë‹µë³€ì„ í° ì»¨í…Œì´ë„ˆì— í‘œì‹œ
- "Show retrieved context" ì²´í¬ë°•ìŠ¤ê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´:
  - ì‚¬ìš©ëœ ëª¨ë“  ì²­í¬ í‘œì‹œ
  - ê° ì²­í¬ì˜ ì¶œì²˜ íŒŒì¼ëª… í‘œì‹œ
  - Expanderë¡œ ì ‘ì–´ì„œ í‘œì‹œ (ê¹”ë”í•œ UI)

## 2-6. RAG ë‹µë³€ ì˜ˆì‹œ

### ì§ˆë¬¸: "Are the thermal gloves warm enough for winter?"

**ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ (3ê°œ ì²­í¬):**
1. review-042.txt: "These gloves are amazing! Kept my hands toasty warm even in -20Â°C..."
2. review-087.txt: "Great warmth and insulation. Perfect for cold winter days..."
3. review-015.txt: "Hands stayed warm throughout the ski trip..."

**ìƒì„±ëœ ë‹µë³€:**
```
Based on customer reviews, the thermal gloves are highly effective for winter use. 
Multiple customers reported that the gloves kept their hands warm in extremely cold 
conditions, including temperatures as low as -20Â°C. Customers specifically mentioned 
"toasty warm hands" and "excellent heat retention" during winter activities like 
skiing. The consensus is that these gloves provide great warmth and insulation for 
cold weather.
```

# 3. í•µì‹¬ í¬ì¸íŠ¸ ë° ê³ ë ¤ì‚¬í•­

## RAGì˜ ì¥ì 

- **ê·¼ê±° ìˆëŠ” ë‹µë³€**: ì‹¤ì œ ê³ ê° ë¦¬ë·°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
- **í™˜ê°(Hallucination) ë°©ì§€**: LLMì´ ë§Œë“¤ì–´ë‚¸ ì •ë³´ê°€ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©
- **ì¶œì²˜ ì¶”ì **: ì–´ë–¤ ë¦¬ë·°ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ëŠ”ì§€ í™•ì¸ ê°€ëŠ¥

## í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

```python
rag_prompt = f"""Answer based ONLY on the provided context.
If the context doesn't contain enough information, say "I don't have enough information."

CONTEXT FROM DOCUMENTS:
{context}

USER QUESTION: {question}
"""
```

- "ONLY on the provided context": LLMì´ ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ë°©ì§€
- ì •ë³´ ë¶€ì¡± ì‹œ ëª…í™•íˆ ë§í•˜ë„ë¡ ì§€ì‹œ
- ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ ëª…í™•íˆ êµ¬ë¶„

## Week 3 RAG íŒŒì´í”„ë¼ì¸ ì™„ì„±

```
Day 16: ë¬¸ì„œ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
   â†“
Day 17: ì²­í¬ë¡œ ë¶„í• 
   â†“
Day 18: ì„ë² ë”© ìƒì„± (ë²¡í„°í™”)
   â†“
Day 19: Cortex Search ì„œë¹„ìŠ¤ ìƒì„±
   â†“
Day 20: ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰
   â†“
Day 21: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± âœ“
```

# ì‹¤í–‰ ê²°ê³¼

## ì‹¤í–‰ ì½”ë“œ

Streamlit ì‹¤í–‰ ì½”ë“œ = python -m streamlit run íŒŒì¼ëª….py

ì˜ˆì‹œ : `python -m streamlit run app/day21.py`

## ê²°ê³¼

- ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ê·¼ê±° ìˆëŠ” ë‹µë³€ ì œê³µ
- ì‹¤ì œ ê³ ê° ë¦¬ë·° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
- ì¶œì²˜ ì¶”ì  ê°€ëŠ¥ (ì–´ë–¤ ë¦¬ë·°ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ëŠ”ì§€)
- í™˜ê° ë°©ì§€ (LLMì´ ë§Œë“¤ì–´ë‚¸ ì •ë³´ê°€ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)

## Week 3 ì™„ë£Œ!

ì´ì œ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì´ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤:
- âœ… ë¬¸ì„œ ì¶”ì¶œ (Day 16)
- âœ… ì²­í¬ ë¶„í•  (Day 17)
- âœ… ì„ë² ë”© ìƒì„± (Day 18)
- âœ… ê²€ìƒ‰ ì„œë¹„ìŠ¤ (Day 19)
- âœ… ê²€ìƒ‰ ì¿¼ë¦¬ (Day 20)
- âœ… ê²€ìƒ‰ ì¿¼ë¦¬ (Day 20)
- âœ… RAG ë‹µë³€ ìƒì„± (Day 21)

---

# ğŸ’¡ ì‹¤ìŠµ ê³¼ì œ (Hands-on Practice)

ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê²°í•©í•˜ì—¬ LLMì—ê²Œ ì „ë‹¬í•  RAG í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ ë´…ë‹ˆë‹¤.

1. f-stringì„ ì‚¬ìš©í•˜ì—¬ `context`ì™€ `question`ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.
2. LLMì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸**ë§Œ**ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ë„ë¡ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”.

# âœ… ì •ë‹µ ì½”ë“œ (Solution)

```python
# RAG í”„ë¡¬í”„íŠ¸ ì‘ì„± ì‹¤ìŠµ
rag_prompt = f"""ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì˜¤ì§ ì•„ë˜ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸(CONTEXT)ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
ë§Œì•½ ì»¨í…ìŠ¤íŠ¸ì— ë‹µë³€í•  ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ì œê³µëœ ë¬¸ì„œì—ëŠ” ê´€ë ¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

[CONTEXT]
{context}

[USER QUESTION]
{question}
"""
```
